% dvips -t letter hw_cov.dvi -o hw_cov.ps ; ps2pdf hw_cov.ps
\documentclass[11pt,titlepage,fleqn]{article}

\input{hw627_header}

\newcommand{\tfile}{{\tt hw\_cov.ipynb}}

\renewcommand{\baselinestretch}{1.1}

%--------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------

\begin{spacing}{1.2}
\centering
{\large \bf Problem Set 4: Covariance functions and Gaussian random fields [cov]} \\
\cltag\ \\
Assigned: February 10, 2022 --- Due: February 16, 2022 \\
Last compiled: \today
\end{spacing}

%------------------------

\subsection*{Overview and instructions}

\begin{enumerate}
\item This problem set deals with three probability distributions: the uniform distribution, the exponential distribution, and the Gaussian distribution.
%These are all examples of {\em generalized Gaussian functions} \citep[][Section 6.6]{Tarantola2005}, which are shown in \refFig{fig:gengauss}.

\item Reading:
\begin{itemize}
\item \citet{Tarantola2005}: Ch.~2 (note Example 2.1) and Sections 5.1, 5.2, 5.3 (note 5.3.3).
\item \citet{Aster}: Appendix B
\item \verb+notes_tarantola.pdf+
\end{itemize}

\item The template notebook is \tfile
\item The function \verb+covC()+ is in \verb+lib_geos.py+. Example plots, such as in \refFig{fig:covC2}, are generated in \verb+covC_plot.ipynb+
\end{enumerate}

% \begin{figure}[h]
% \centering
% \includegraphics[width=13cm]{hw_cov_gauss_gen.eps}
% \caption[]
% {{
% Generalized Gaussian functions, as illustrated in Figure 6.6 of \citet{Tarantola2005}.
% These are plots of Eq.~6.68 for $p = 1, 2, 10, 1000$, which include the exponential distribution ($p=1$), the Gaussian distribution ($p=2$), and the uniform distribution ($p \rightarrow \infty$). The parameter $\sigma$ is the $\sigma_p$ of \citet[][eq.~6.53]{Tarantola2005}; it corresponds to the variance only when $p=2$.
% \label{fig:gengauss}
% }}
% \end{figure}

%------------------------

%\pagebreak
\subsection*{Problem 1 (1.0). Gaussian and exponential PDFs}

% The exponential and Gaussian probability density functions are given by \citep[\eg][Appendix~B]{Aster}
% %
% \begin{eqnarray}
% f_1(x) &=& \frac{1}{\sigma\sqrt{2}} \exp\left(-\frac{\sqrt{2}|x - \mu|}{\sigma} \right)
% \\
% f_2(x) &=& \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2} \right)
% \end{eqnarray}

\begin{enumerate}

% XXX MAKE THIS PROBLEM WORTH MORE POINTS IN THE FIGURE XXX
\item (0.5) Consider the normal distribution $f_N(x)$.
\begin{enumerate}
\item (0.1) What is the exact expression and approximate value\footnote{By ``approximate'', I mean to use decimal numbers in the expression (as in 0.717 instead of $e^{-3}$).} of $f_N(\mu\pm\sigma)$?
\item (0.1) What is the exact expression and approximate value of $f_N(\mu)$?
\item (0.1) Sketch or make a plot of $f_N(x)$. (If you're plotting, then use $\mu = 0$ and $\sigma = 1$.)
\item (0.2) Label $\sigma$, $\mu$, and $f_N(\pm\sigma)$ on your plot, and plot the three points $(\mu,f_N(\mu))$, $(-\sigma,f_N(-\sigma))$, and $(\sigma,f_N(\sigma))$.
\end{enumerate}

%------------

\item (0.2) Consider the exponential probability density function
%
\begin{eqnarray}
f(x) &=& k\,\exp\left(-\frac{\sqrt{2}|x - \mu|}{\sigma} \right)
\end{eqnarray}
%
Show that $k = 1/(\sigma\sqrt{2})$.

Hint: Split the integration into two intervals in order to eliminate the absolute values.

%------------

\item (0.3) Consider the two Gaussian probability density functions
%
\begin{eqnarray}
f_X(x) &=& k_x \exp\left(-\frac{(x-\mu_x)^2}{2\sigma_x^2} \right)
\\
f_Y(y) &=& k_y \exp\left(-\frac{(y-\mu_y)^2}{2\sigma_y^2} \right)
\end{eqnarray}
%
\begin{enumerate}
\item (0.1) Assuming that the variables $X$ and $Y$ are independent, what is the joint probability density function $f(x,y)$?
\item (0.2) Assuming that the mean is zero and that $f(x,y)$ has circular level surfaces, show that the normalization factor for $f(x,y)$ is $h = 1/(2\pi\sigma^2)$ (such that $f(x,y) = h\,g(x,y)$).
\end{enumerate}

Hints:
\begin{itemize}
\item \citet[][eq. B.28]{Aster}
\item What does ``mean zero'' and ``circular Gaussian'' imply about $f(x,y)$?
\item Try the integration using polar coordinates (it is clean).
\end{itemize}

%------------------

\end{enumerate}

%------------------------

%\pagebreak
\subsection*{Problem 2 (2.5). Uniform PDF (and central limit theorem)}

The formulas for expected value and variance are given by
%
\begin{eqnarray}
E[X] &=& \int_{-\infty}^{\infty} x\;f_X(x) \,dx
\label{EX}
\\
\Var[X] &=& E[X^2] - (E[X])^2
\label{var}
\end{eqnarray}
%
where $f_X(x)$ is a probability density function. The expectated value of $g(X)$ is given by
%
\begin{eqnarray}
E[g(X)] &=& \int_{-\infty}^{\infty} g(x)\;f_X(x) \,dx
\label{Egx}
\end{eqnarray}

%=============================

\begin{enumerate}
\item (0.2) Write the expression for a uniform distribution, $f_U(x)$, on the interval $[a,b]$. \\
Write the command to generate $n$ samples of $f_U(x)$.
\label{fu}

%------------------

\item (1.0) Using \refEqab{EX}{Egx} (with your $f_U(x)$ in place of $f_X(x)$), show that the expected value and variance for $f_U(x)$ are given by
%
\begin{eqnarray}
E[X] &=& \frac{a+b}{2}
\\
\Var[X] &=& \frac{(b-a)^2}{12}
\end{eqnarray}
%
Hint: You will probably need to use polynomial long division.

%------------------

%\pagebreak
\item (0.0) In Python, generate $10^5$ or so samples of $f_U(x)$ (remember: a sample of $f_U(x)$ will be a random number between $a$ and $b$), and check that the mean ($\mu$) and variance ($\sigma^2$) of the samples are close to the theoretical values, \ie $\mu \approx E[X]$ and $\sigma^2 \approx \Var[X]$. For the sake of comparison, use
%
\begin{equation*}
a = -\sqrt{12},
\hspace{1cm}
b = 5\sqrt{12}
\end{equation*}
%\begin{eqnarray*}
%a &=& -\sqrt{12}
%\\
%b &=& 5\sqrt{12}
%\end{eqnarray*}
%
{\bf Plot a histogram of your samples} to check that the distribution is flat over the appropriate interval. (No need to turn in this plot.)

%------------------

\pagebreak
\item (1.3) The {\bf central limit theorem} is stated in \citet[][Section B.6]{Aster}:
%
\begin{quote}
Let $X_1$, $X_2$, \ldots, $X_n$ be independent and identically distributed (IID) random variables with a finite expected value $\mu$ and variance $\sigma^2$. Let
%
\begin{equation}
Z_n = \frac{X_1 + X_2 + \cdots + X_n - n\mu}{\sigma\sqrt{n}}.
\label{Zn}
\end{equation}
%
In the limit as $n$ approaches infinity, the distribution of $Z_n$ approaches the standard normal distribution.
\end{quote}

The central limit theorem works for any kind of distribution. You will demonstrate it using the uniform distribution, $f_U(x)$ (Problem 2-\ref{fu}), for which you know $\mu$ and $\sigma$.

\begin{enumerate}

\item (0.1)
\begin{itemize}
\item Write the expression for $Z_1$.
\item What are the minimum and maximum values of $Z_1$? \\
Note: Your answer should not have $\mu$ or $\sigma$ in the expressions, since these can be written in terms of $a$ and $b$.
\end{itemize}

\item (0.4)
\begin{itemize}
\item Write the expression for $Z_2$.
\item What are the minimum and maximum possible values of the sum $X_1 + X_2$? \\
Note: Your answer should not have $\mu$ or $\sigma$ in the expressions, since these can be written in terms of $a$ and $b$.
\item What are the minimum and maximum values of $Z_2$?
\end{itemize}

\item (0.8) \ptag\ By generating samples ($X$) from your $f_U(x)$, demonstrate the central limit theorem by showing a set of histograms of $Z_1$, $Z_2$, $Z_3$, and $Z_{10}$. To obtain each distribution of $Z_n$ (\refeq{Zn}), you will need to repeat the experiment $p$ times; try $p = 10^5$. Center your histograms between $\pm 4$.

Hint:
\begin{itemize}
\item Consider the case of $n=2$. The first ``experiment'' will involve generating two random samples, $X_1$ and $X_2$, of $f_U(x)$. You can then compute $Z_2$ using \refEq{Zn}. You then repeat this process $p$ times and plot a histogram of the $p$ values of $Z_2$.
\end{itemize}

\end{enumerate}

\end{enumerate}

%------------------------

\pagebreak
\subsection*{Problem 3 (4.0). Estimating a covariance matrix from a set of samples}

See the template script \tfile. Let $\nsample$ be the number of samples and $\nparm$ be the number of model parameters describing a single sample. The $j$th sample is represented by the $\nparm \times 1$ vector
%
\begin{equation}
\bem_j = \bmu + \bem_j^{\rm C}
\label{mj}
\end{equation}
%
where $\bmu$ is a mean vector and $\bem_j^{\rm C}$ is a sample generated from covariance matrix $\bC$.

It may (or may not) help to attach some physical meaning to these $\bem_j$ samples. Think of each sample as the functional variation in a single dimension. The set of $\nsample$ samples might represent, for example:
%
\begin{itemize}
\item the variation in topography along different transects.

\item the variation in height of an interval of an oscillating wire: each profile represents a different snapshot in time.

\item the variation of vertical ground displacement with time, as captured by a seismogram: each profile is for a different earthquake, recorded at the same station.

\end{itemize}
%
Our subscript notation for $\bmu_\nsample$ and $\bC_\nsample$ denotes that these quantities are estimated from a set of $\nsample$ samples $\bem_j$.

\medskip\noindent
\textcolor{red}{In this problem, the goal is to compute a sample covariance matrix $\bC_\nsample$ from $\nsample$ samples. In Problem~4, the goal is to use $\bC_\nsample$ to estimate the covariance function $C(d)$ that characterizes the samples, where $d$ is the distance between two points.}

%--------------

\begin{enumerate}

\item (0.0) Run \tfile. Identify the key variables (and their dimensions) that are loaded. This should be helpful:
%
\begin{eqnarray}
\bM &=& 
\left[ \begin{array}{cccccc}
| & | & | & | & | & | \\
\bem_1 & \bem_2 & \cdots & \bem_j & \cdots & \bem_\nsample \\
| & | & | & | & | & | \\
\end{array} \right],
\end{eqnarray}
%
where $\bem_j$ is the $j$th sample.

% XXX MAKE THIS WORTH MORE POINTS XXX
\item (0.3) Plot 8 samples in a $4 \times 2$ subplot figure, with one sample per subplot and with the same axis scale for each subplot (use \verb+ax0+ from \tfile). Plot each sample using the spatial discretization given by \verb+x+. Either use a default plotting style or \verb+'-.'+(but not \verb+'.'+).

{\em For all $\nparm$-dimensional vectors in the rest of the problem, plot them using the same $y$-axis range and with the spatial discretization given by \verb+x+.}

\label{samps}

%--------------

\item (1.5) Use the first $\nsample=10$ samples to do the following:
%
\begin{enumerate}
\item (0.3) Compute and plot the mean, $\bmu_{10}$.
\item (0.7) Compute and plot the covariance matrix, $\bC_{10}$ (use \verb+imshow+). Show your code to compute $\bC_{10}$, and do not use the black-box \verb+cov+ function\footnote{If you use {\tt cov} to check, you may need to transpose your matrix of samples to ensure that the resultant matrix is $\nparm \times \nparm$.}.
\item (0.5) Make a scatterplot (use \verb+plot+) of $(\bC_{10})_{kk'}$ versus $D_{kk'} = |x_k - x_{k'}|$, where $\bD$ is provided in \tfile. 

Hint: Try \verb+plt.plot(D,Csamp,'b.')+ where \verb+Csamp+ represents $\bC_{10}$.
\end{enumerate}

%--------------

\item (0.5) Repeat the previous (include plots), but use all 1000 samples. How does the estimated mean and covariance change with increasing the number of samples?

\label{prob:Cd}

%--------------

\item (0.4) Examine the function \verb+covC()+.
%, which will be needed in Problems 3-\ref{prob:covC} and 4.
Some example plots using \verb+covC()+ are shown in \refFig{fig:covC2}. Two of the functions plotted are \refEqii{Cgaus1}{Cexp1} (see \refApp{sec:matern}), where $d$ is the distance between $\br$ and $\br'$. In our 1D example, $d(\br,\br') = d(x,x') = |x - x'|$.
%The function \verb+covC()+ inputs $L'$ (assuming that \verb+LFACTOR=2+).
%
$C$~takes in a distance between two points and outputs a value. It can alternatively be written as a function of the two input points, $x$ and $x'$:
%
\begin{eqnarray}
C_{\rm gaus}(x,x') &=&
\sigma^2 \exp \left( - \frac{2 (x-x')^2}{L'^2} \right) 
\\
C_{\rm exp}(x,x') &=&
\sigma^2 \exp \left( - \frac{2 |x-x'|}{L'} \right)
,
\end{eqnarray}
%
or in discrete form
%
\begin{eqnarray}
(C_{\rm gaus})_{kk'} &=& C_{\rm gaus}(x_k,x_{k'}) =
\sigma^2 \exp \left( - \frac{2 (x_k-x_{k'})^2}{L'^2} \right) 
\\
(C_{\rm exp})_{kk'} &=& C_{\rm exp}(x_k,x_{k'}) =
\sigma^2 \exp \left( - \frac{2 |x_k-x_{k'}|}{L'} \right)
,
\end{eqnarray}

\begin{enumerate}
\item What are $C_{\rm gaus}$ and $C_{\rm exp}$ for two points separated by $d = L'$?
\item What are $C_{\rm gaus}$ and $C_{\rm exp}$ for two points separated by $d = L'/2$?
\item What are $C_{\rm gaus}$ and $C_{\rm exp}$ for two points separated by $d = 0$?
\item What values of $\sigma^2$ and $L'$ were used for \refFig{fig:covC2}?
\end{enumerate}
%
Note: Only integers and variables should appear in your answers.

%--------------

\item (0.0) Run the example listed in \verb+covC()+ and make sure you understand what the input parameters are.

%--------------

\item (0.8) Use \verb+covC()+ to find a covariance function $C(d)$ that reasonably fits the scatterplot of $(\bC_{1000})_{kk'}$ versus $D_{kk'}$ from Problem 3-\ref{prob:Cd}.
%
\begin{enumerate}
\item List your values of the parameters that describe $C(d)$.
\item Include a plot with $C(d)$ superimposed on the scatterplot of $(\bC_{1000})_{kk'}$ versus $D_{kk'}$.
\item Let $\bC$ be the covariance matrix corresponding to $C(d)$. \\
What are the diagonal entries of $\bC$ and why?
\item Include a plot of $\bC$ (use \verb+imshow+).
\end{enumerate}

\label{prob:covC}

\end{enumerate}

%------------------------

\pagebreak
\subsection*{Problem 4 (2.5). Generating samples from a prescribed covariance}

\citet[][p.~45]{Tarantola2005}:
%
\begin{quote}
\ldots a large enough number of realizations completely characterizes the [Gaussian random] field\ldots Displaying the mean of the Gaussian random field and plotting the covariance is {\em not} an alternative to displaying a certain number of realizations, because the mean and covariance do not relate in an intuitive way to the realizations.
\end{quote}

\noindent
In Problem 3, you used a set of 1000 samples and computed a mean $\bmu_{1000}$ and a covariance matrix $\bC_{1000}$. You used $\bC_{1000}$ to estimate a covariance function $C(d)$ with corresponding covariance matrix $\bC$. Here you will use $\bmu_{1000}$ and $\bC$ (not $\bC_{1000}$) to generate a set of samples that (hopefully) resembles the original samples.

%\pagebreak
\begin{enumerate}
\item (1.5) 

\begin{enumerate}
\item (1.0) Generate 2000 samples of $\bC$, and save these as a set of $\bem^{\rm C}$ (each $\bem_j^{\rm C}$ is still $\nparm \times 1$). {\bf Include the pertinent lines of your code.}

Hints:
%
\begin{itemize}
\item \verb+A = np.linalg.cholesky(C)+
%\item \verb+A = chol(C,'lower');+
\item If $\bx = \bA\bw$ is a sample of $\bC$, what are $\bA$ and $\bw$?
\item You may want to use the suffix \verb+.flatten()+ when saving each sample $\bx$ into a matrix of samples.
\end{itemize}

\item (0.4) Add $\bmu_{1000}$ to each $\bem^{\rm C}$, then plot the first 8 samples (as in Problem 3-\ref{samps}). \\
Superimpose $\bmu_{1000}$ in each subplot.

\item (0.1) Do your samples resemble those provided in Problem 3? (yes or no)
\end{enumerate}

%----------

\item (0.5) Consider the samples of the covariance matrix $\bem_j^{\rm C}$. (Note: these differ from $\bem_j$, see \refeq{mj}.)

Compute the mean (\verb+mean+), standard deviation (\verb+std+), and norm of each of the 2000 $\bem^{\rm C}$, and show your results in three histogram plots. Do your results check with what you expect?

NOTE: Python's \verb+norm+ command will {\em not} be useful here. In calculating the norm, you will need to use a modified covariance matrix, $\nparm\bC$, where $\nparm\times\nparm$ is the dimension of $\bC$. This will ensure that the norm of each $\bem^{\rm C}$ is about~1.

%----------

\item (0.8) \ptag\ Now generate a new $\bC$ using \verb+covC()+ by making {\em only} one change: change \verb+icov+ to either 1 or 2. Repeat Problem 4-1 using the same set of Gassian random vectors $\bw_j$, as before. This will allow for a true comparison between samples from the Gaussian or exponential covariance functions.

\begin{enumerate}
\item Generate samples of the new $\bC$, add $\bmu_{1000}$ to each sample. Plot the the first 8 samples.

\item Describe the differences and similarities between the samples from the two different distributions.

\end{enumerate}

%----------

\item (0.2) \ptag\ Repeat Problem 4-2 for the set of 2000 samples from the new $\bC$.

\end{enumerate}

%------------------------

\pagebreak
\subsection*{Problem} \howmuchtime\

\bibliography{carl_abbrev,carl_main,carl_source,carl_him,carl_alaska}

%-------------------------------------------------------------

\pagebreak

\appendix

\section{The length scale factor in {\tt covC()}}
\label{sec:matern}

\refFig{fig:covC2} is generated by \verb+covC_plot.ipynb+, which calls \verb+covC()+, which resides in \verb+lib_geos.py+. It shows examples of four types of covariance functions: Gaussian, exponential, circular, and Mat\'ern. The first three are listed in \citet[][p.~111-113]{Tarantola2005}, and the Mat\'ern definition can be found in Wikipedia. The Gaussian and exponential functions are:
%
\begin{eqnarray}
C_{\rm gaus}(d) &=& \sigma^2 \exp \left( - \frac{ d^2}{2L^2} \right)
\label{Cgaus0}
\\
C_{\rm exp}(d) &=& \sigma^2 \exp \left( - \frac{d}{L} \right)
\label{Cexp0}
\end{eqnarray}
%
Redefining the length scale as
%
\begin{equation}
L' = 2L,
\end{equation}
%
we get
%
\begin{eqnarray*}
C_{\rm gaus}(d) &=& \sigma^2 \exp \left( - \frac{ d^2}{2(L'/2)^2} \right) 
= \sigma^2 \exp \left( - \frac{2 d^2}{L'^2} \right) 
\\
C_{\rm exp}(d) &=& \sigma^2 \exp \left( - \frac{d}{L'/2} \right)
= \sigma^2 \exp \left( - \frac{2 d}{L'} \right)
\end{eqnarray*}
%
Adopting $L'$ as the length scale, we can list all four covariance functions:
%
\begin{eqnarray}
C_{\rm gaus}(d) &=& \sigma^2 \exp \left( - \frac{2 d^2}{L'^2} \right) 
\label{Cgaus1}
\\
C_{\rm exp}(d) &=& \sigma^2 \exp \left( - \frac{2 d}{L'} \right)
\label{Cexp1}
\\
C_{\rm circ}(d) &=& \left\{
\begin{array}{ll}
\sigma^2\left(1 - \frac{\beta + \sin\beta}{\pi} \right) & d \le L'
\\
0 \;\;\;\; & d > L'
\end{array}
\right.
\\
\beta &=& 2 \sin^{-1}\left( \frac{r}{L'} \right)
\nonumber
\\
C_\nu(d) &=& \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\sqrt{2\nu}\frac{d}{L'} \right)^\nu K_\nu\left(\sqrt{2\nu} \frac{d}{L'}\right),
\end{eqnarray}
%
where $\Gamma$ is the gamma function, $K_\nu$ is the modified Bessel function of the second kind, and $\nu$ is a positive number. The value of $C(L')$ are similar for all four covariance functions, as desired.

We will work with $L'$ in the equations and \verb+Lprime+ in the code.

%-------------------------------------------------------------

% generated in covC_plot.m
\clearpage\pagebreak
\begin{figure}
\centering
\includegraphics[width=15cm]{covC_LFACTOR2.eps}
\caption[]
{{
Covariance functions from {\tt covC()} characterized by length scale $L'$ and amplitude $\sigma^2$.
See \citet[][Section 5.3.3, p. 113]{Tarantola2005}.
Some reference $e$-folding depths are labeled; for example, the $y$-values of the top line is $y = \sigma^2 e^{-1/2} \approx 9.70$.
The Mat\'ern covariance functions include an additional parameter $\nu$ that influences the shape: $\nu \rightarrow \infty$ for the Gaussian function (upper left), $\nu = 0.5$ for the exponential function (upper right).
\label{fig:covC2}
}}
\end{figure}

\iffalse
% generated in covC_plot.m
\clearpage\pagebreak
\begin{figure}
\centering
\includegraphics[width=15cm]{covC_LFACTOR1.eps}
\caption[]
{{
Same as \refFig{fig:covC2}, but for LFACTOR = 1.
\label{fig:covC1}
}}
\end{figure}
\fi

%-------------------------------------------------------------
\end{document}
%-------------------------------------------------------------
